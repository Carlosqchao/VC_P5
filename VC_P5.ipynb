{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa15027",
   "metadata": {},
   "source": [
    "EMOTION RECOGNITION MODEL - FER2013\n",
    "\n",
    "DESCRIPCIÓN GENERAL\n",
    "Este notebook entrena un modelo de Red Neuronal Convolucional (CNN) para reconocer emociones en imágenes faciales usando el dataset FER2013. El modelo es capaz de clasificar imágenes en 7 categorías de emociones diferentes.\n",
    "\n",
    "FUNCIONALIDADES PRINCIPALES\n",
    "\n",
    "1. CARGA Y PREPARACIÓN DE DATOS\n",
    "- Carga de imágenes desde directorio de entrenamiento y prueba\n",
    "- Aplicación de Data Augmentation en el conjunto de entrenamiento\n",
    "- Normalización de imágenes (escala 0-1)\n",
    "- Generadores de datos para procesamiento eficiente en lotes\n",
    "\n",
    "2. ARQUITECTURA DEL MODELO CNN\n",
    "- 4 bloques convolucionales con capas de convolución, normalización de lotes y dropout\n",
    "- Pooling progresivo para reducción de dimensionalidad\n",
    "- Capas densas (fully connected) para clasificación final\n",
    "- Softmax para salida probabilística de 7 clases\n",
    "\n",
    "3. ENTRENAMIENTO\n",
    "- Optimizador: Adam (learning rate: 0.0001)\n",
    "- Loss: Categorical Crossentropy\n",
    "- Callbacks incluyen:\n",
    "  - Early Stopping (paciencia: 10 epochs)\n",
    "  - Reducción de tasa de aprendizaje (ReduceLROnPlateau)\n",
    "  - Guardado del mejor modelo (ModelCheckpoint)\n",
    "\n",
    "4. EMOCIONES DETECTADAS\n",
    "1. Angry (Enojado)\n",
    "2. Disgust (Asqueado)\n",
    "3. Fear (Asustado)\n",
    "4. Happy (Feliz)\n",
    "5. Neutral (Neutral)\n",
    "6. Sad (Triste)\n",
    "7. Surprise (Sorprendido)\n",
    "\n",
    "5. EVALUACIÓN Y VISUALIZACIÓN\n",
    "- Matriz de confusión\n",
    "- Reporte de clasificación (precisión, recall, f1-score)\n",
    "- Gráficos de accuracy y loss durante el entrenamiento\n",
    "- Función de predicción para imágenes individuales\n",
    "\n",
    "6. OUTPUTS\n",
    "- best_emotion_model.h5: Mejor modelo guardado durante el entrenamiento\n",
    "- final_emotion_model.h5: Modelo final después de todos los epochs\n",
    "- training_history.png: Gráficos de entrenamiento\n",
    "- confusion_matrix.png: Matriz de confusión del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed174f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'VC_P5 (Python 3.11.5)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'conda install -n VC_P5 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# Configuración de rutas - ajusta según tu estructura en Kaggle\n",
    "TRAIN_DIR = '/kaggle/input/fer2013/train'\n",
    "TEST_DIR = '/kaggle/input/fer2013/test'\n",
    "IMG_SIZE = 48\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "\n",
    "# Clases de emociones\n",
    "emotions = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "num_classes = len(emotions)\n",
    "\n",
    "# Data Augmentation para entrenamiento\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Solo normalización para validación/test\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generadores de datos\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Clases encontradas: {train_generator.class_indices}\")\n",
    "print(f\"Imágenes de entrenamiento: {train_generator.samples}\")\n",
    "print(f\"Imágenes de prueba: {test_generator.samples}\")\n",
    "\n",
    "# Construcción del modelo CNN\n",
    "def create_emotion_cnn():\n",
    "    model = keras.Sequential([\n",
    "        # Bloque 1\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Bloque 2\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Bloque 3\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Bloque 4\n",
    "        layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Capas densas\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Crear y compilar el modelo\n",
    "model = create_emotion_cnn()\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_emotion_model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Guardar el modelo final\n",
    "model.save('final_emotion_model.h5')\n",
    "print(\"Modelo guardado exitosamente!\")\n",
    "\n",
    "# Visualizar resultados del entrenamiento\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Evaluación del modelo\n",
    "print(\"\\n=== Evaluación en el conjunto de prueba ===\")\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Predicciones para la matriz de confusión\n",
    "test_generator.reset()\n",
    "predictions = model.predict(test_generator, steps=len(test_generator))\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Reporte de clasificación\n",
    "print(\"\\n=== Reporte de Clasificación ===\")\n",
    "print(classification_report(y_true, y_pred, target_names=emotions))\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=emotions, yticklabels=emotions)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Función para predecir emociones en imágenes individuales\n",
    "def predict_emotion(image_path):\n",
    "    \"\"\"\n",
    "    Predice la emoción de una imagen individual\n",
    "    \"\"\"\n",
    "    img = keras.preprocessing.image.load_img(\n",
    "        image_path, \n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        color_mode='grayscale'\n",
    "    )\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = img_array / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    prediction = model.predict(img_array, verbose=0)\n",
    "    emotion_idx = np.argmax(prediction)\n",
    "    confidence = prediction[0][emotion_idx]\n",
    "    \n",
    "    return emotions[emotion_idx], confidence\n",
    "\n",
    "# Ejemplo de uso de la función de predicción\n",
    "# emotion, conf = predict_emotion('path/to/image.jpg')\n",
    "# print(f\"Emoción detectada: {emotion} (Confianza: {conf:.2%})\")\n",
    "\n",
    "print(\"\\n¡Entrenamiento completado exitosamente!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
